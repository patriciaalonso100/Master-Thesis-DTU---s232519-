{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8eada24f-abd5-4b46-84bf-8132b7334bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import hashlib\n",
    "from dataclasses import dataclass\n",
    "import ast\n",
    "import ipaddress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ec5cba7-582c-4eac-918e-11afb4a86baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class BuildConfig:\n",
    "    golden_id: str = \"episode_016\"\n",
    "\n",
    "    duplicate_prone_streams: tuple = (\"cisco_ise.log\", \"cisco_asa.log\")\n",
    "    evidence_hash_len: int = 16\n",
    "\n",
    "    episodes_dirname: str = \"episodes\"   \n",
    "    dataset_dirname: str = \"data\"        \n",
    "    unified_parquet_name: str = \"episodes_all_baseline.parquet\"\n",
    "\n",
    "cfg = BuildConfig()\n",
    "\n",
    "NOTEBOOK_DIR = Path.cwd()\n",
    "PROJECT_DIR  = NOTEBOOK_DIR.parent\n",
    "\n",
    "OUTPUT_DIR = PROJECT_DIR / cfg.episodes_dirname\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "DATASET_DIR = PROJECT_DIR / cfg.dataset_dirname\n",
    "DATASET_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d96b2e3-cf66-4dd5-8015-b04f729db2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def short_hash(x) -> str:\n",
    "    if x is None:\n",
    "        return \"none\"\n",
    "    try:\n",
    "        if pd.isna(x):\n",
    "            return \"none\"\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    s = str(x).strip()\n",
    "    if not s or s.lower() in (\"nan\", \"none\"):\n",
    "        return \"none\"\n",
    "    return hashlib.sha256(s.encode(\"utf-8\")).hexdigest()[:12]\n",
    "\n",
    "\n",
    "def _is_empty(x) -> bool:\n",
    "    if x is None:\n",
    "        return True\n",
    "    try:\n",
    "        if pd.isna(x):\n",
    "            return True\n",
    "    except Exception:\n",
    "        pass\n",
    "    s = str(x).strip().lower()\n",
    "    return s in (\"\", \"nan\", \"none\")\n",
    "\n",
    "\n",
    "def as_list(x) -> list[str]:\n",
    "    if _is_empty(x):\n",
    "        return []\n",
    "\n",
    "    if isinstance(x, (list, tuple, set)):\n",
    "        return [str(v) for v in x if not _is_empty(v)]\n",
    "\n",
    "    if isinstance(x, str):\n",
    "        s = x.strip()\n",
    "        if s.startswith(\"[\") and s.endswith(\"]\"):\n",
    "            try:\n",
    "                parsed = ast.literal_eval(s)\n",
    "                if isinstance(parsed, list):\n",
    "                    return [str(v) for v in parsed if not _is_empty(v)]\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "    return [str(x)]\n",
    "\n",
    "\n",
    "def norm_token(x, default: str = \"unknown\") -> str:\n",
    "    if _is_empty(x):\n",
    "        return default\n",
    "    return str(x).strip().lower()\n",
    "\n",
    "\n",
    "def join_tokens(x, default: str = \"unknown\") -> str:\n",
    "    vals = [str(v).strip().lower() for v in as_list(x)]\n",
    "    vals = [v for v in vals if v and v not in (\"nan\", \"none\")]\n",
    "    if not vals:\n",
    "        return default\n",
    "    vals = sorted(set(vals))\n",
    "    return \"+\".join(vals)\n",
    "\n",
    "\n",
    "def dport_bucket(dport_raw) -> str:\n",
    "    d = str(dport_raw).split(\".\")[0].strip()\n",
    "    if d in (\"22\", \"2222\"):\n",
    "        return \"ssh\"\n",
    "    if d.lower() in (\"\", \"nan\", \"none\"):\n",
    "        return \"unknown\"\n",
    "    return \"*\"\n",
    "\n",
    "\n",
    "def safe_col(df: pd.DataFrame, col: str, default=\"\") -> pd.Series:\n",
    "    if col in df.columns:\n",
    "        return df[col]\n",
    "    return pd.Series([default] * len(df), index=df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1dfaa5c-3120-439c-acbe-900affb66e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_masked_message_cl(row: dict) -> str:\n",
    "    ds = (str(row.get(\"data_stream.dataset\", \"\")).strip() or \"unknown_stream\").lower()\n",
    "\n",
    "    # Generic semantic tokens\n",
    "    act   = join_tokens(row.get(\"event.action\"),   default=\"unknown\")\n",
    "    cat   = join_tokens(row.get(\"event.category\"), default=\"unknown\")\n",
    "    out   = norm_token(row.get(\"event.outcome\"),   default=\"unknown\")\n",
    "    code  = norm_token(row.get(\"event.code\"),      default=\"none\")\n",
    "\n",
    "    # Semantic richness\n",
    "    kind  = join_tokens(row.get(\"event.kind\"), default=\"unknown\")\n",
    "    etype = join_tokens(row.get(\"event.type\"), default=\"unknown\")\n",
    "\n",
    "    # Network-ish tokens\n",
    "    tr    = norm_token(row.get(\"network.transport\"), default=\"unknown\")\n",
    "    direction = norm_token(row.get(\"network.direction\"), default=\"unknown\")\n",
    "    dp    = dport_bucket(row.get(\"destination.port\", \"\"))\n",
    "\n",
    "    msg = norm_token(row.get(\"message\"), default=\"\")\n",
    "\n",
    "    # Base prefix\n",
    "    base = f\"[{ds}] kind={kind} type={etype} cat={cat} act={act} out={out} code={code} dport={dp} tr={tr} dir={direction}\"\n",
    "\n",
    "    # elastic_agent.filebeat \n",
    "    if ds == \"elastic_agent.filebeat\":\n",
    "        lvl = norm_token(row.get(\"log.level\"), default=\"unknown\")\n",
    "        return f\"{base} lvl={lvl}\"\n",
    "\n",
    "    # system.auth \n",
    "    if ds == \"system.auth\":\n",
    "        proc = norm_token(row.get(\"process.name\"), default=\"unknown\")\n",
    "        ssh_method = norm_token(row.get(\"system.auth.ssh.method\"), default=\"unknown\")\n",
    "\n",
    "        cat_list = [t.lower() for t in as_list(row.get(\"event.category\"))]\n",
    "        act_list = [t.lower() for t in as_list(row.get(\"event.action\"))]\n",
    "\n",
    "        ev = \"other\"\n",
    "        if \"connection closed\" in msg or \"connection reset\" in msg or \"broken pipe\" in msg:\n",
    "            ev = \"conn_err\"\n",
    "        elif \"authentication\" in cat_list and out == \"failure\":\n",
    "            ev = \"auth_fail\"\n",
    "        elif \"authentication\" in cat_list and out == \"success\":\n",
    "            ev = \"auth_ok\"\n",
    "\n",
    "        if \"sshd\" in proc:\n",
    "            if \"authentication\" in cat_list and any(a in (\"ssh_login\", \"user_login\") for a in act_list):\n",
    "                if \"password\" in ssh_method:\n",
    "                    return f\"{base} proc=sshd ssh_method=password ev={ev} user=* from=*\"\n",
    "                return f\"{base} proc=sshd ssh_method=other ev={ev} user=* from=*\"\n",
    "\n",
    "            return f\"{base} proc=sshd ssh_method={ssh_method} ev={ev} user=* from=*\"\n",
    "\n",
    "        if \"sudo\" in proc:\n",
    "            return f\"{base} proc=sudo ev={ev} user=* cmd=*\"\n",
    "        if \"systemd\" in proc:\n",
    "            return f\"{base} proc=systemd ev={ev}\"\n",
    "\n",
    "        return f\"{base} proc=other ev={ev}\"\n",
    "\n",
    "    # endpoint.events.* \n",
    "    if ds == \"endpoint.events.network\" or \"endpoint.events\" in ds:\n",
    "        act_n = str(len([p for p in act.split(\"+\") if p.strip()])) if act != \"unknown\" else \"unknown\"\n",
    "        return f\"{base} act_n={act_n}\"\n",
    "\n",
    "    # panw.panos \n",
    "    if ds == \"panw.panos\":\n",
    "        pan_act = norm_token(row.get(\"panw.panos.action\"), default=\"\")\n",
    "        if pan_act not in (\"\", \"unknown\", \"none\"):\n",
    "            fw = pan_act\n",
    "        else:\n",
    "            fw = \"allow\" if act in (\"flow_started\", \"flow-started\", \"flow-created\", \"flow_created\", \"allow\", \"permit\") else \"deny\"\n",
    "\n",
    "        pan_type = norm_token(row.get(\"panw.panos.type\"), default=\"unknown\")\n",
    "        pan_sub  = norm_token(row.get(\"panw.panos.sub_type\"), default=\"unknown\")\n",
    "        endr     = norm_token(row.get(\"panw.panos.endreason\"), default=\"unknown\")\n",
    "        app      = norm_token(row.get(\"network.application\"), default=\"unknown\")\n",
    "\n",
    "        return f\"{base} fw={fw} ptype={pan_type} psub={pan_sub} endr={endr} app={app}\"\n",
    "\n",
    "    # cisco_asa.log \n",
    "    if ds == \"cisco_asa.log\":\n",
    "        term = norm_token(row.get(\"cisco.asa.termination_initiator\"), default=\"unknown\")\n",
    "        return f\"{base} term={term}\"\n",
    "\n",
    "    # cisco_ise.log \n",
    "    if ds == \"cisco_ise.log\":\n",
    "        pkt  = norm_token(row.get(\"cisco_ise.log.radius.packet.type\"), default=\"unknown\")\n",
    "        step = norm_token(row.get(\"cisco_ise.log.step\"), default=\"unknown\")\n",
    "        authm = norm_token(row.get(\"cisco_ise.log.authentication.method\"), default=\"unknown\")\n",
    "        svc   = norm_token(row.get(\"service.type\"), default=\"unknown\")\n",
    "\n",
    "        ise_ev = \"generic\"\n",
    "        if \"accounting\" in msg:\n",
    "            ise_ev = \"accounting\"\n",
    "        elif \"success\" in out or \"passed\" in act:\n",
    "            ise_ev = \"auth_ok\"\n",
    "        elif \"fail\" in out or \"failure\" in out or \"failed\" in msg or \"failure\" in msg:\n",
    "            ise_ev = \"auth_fail\"\n",
    "\n",
    "        return f\"{base} ise_ev={ise_ev} pkt={pkt} step={step} authm={authm} svc={svc} user=* nas=*\"\n",
    "\n",
    "    # system.security\n",
    "    if ds == \"system.security\":\n",
    "        logon_type = norm_token(row.get(\"winlog.logon.type\"), default=\"unknown\")\n",
    "        return f\"{base} logon={logon_type}\"\n",
    "\n",
    "    return base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05910c94-6ee1-4c1d-8d93-60d44765db75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_ip(s: str) -> bool:\n",
    "    try:\n",
    "        ipaddress.ip_address(str(s).strip())\n",
    "        return True\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def extract_actor_ip(row: dict) -> str:\n",
    "    ds = str(row.get(\"data_stream.dataset\", \"\")).strip().lower()\n",
    "\n",
    "    def _first_ip(*vals) -> str:\n",
    "        for v in vals:\n",
    "            for x in as_list(v):\n",
    "                s = str(x).strip()\n",
    "                if s and is_ip(s):\n",
    "                    return s\n",
    "        return \"none\"\n",
    "\n",
    "\n",
    "    if ds != \"cisco_ise.log\":\n",
    "        return _first_ip(row.get(\"source.ip\"), row.get(\"source.address\"))\n",
    "\n",
    "\n",
    "    framed_ip = _first_ip(\n",
    "        row.get(\"cisco_ise.log.framed.ip\"),\n",
    "    )\n",
    "    if framed_ip != \"none\":\n",
    "        return framed_ip\n",
    "\n",
    "    client_ip = _first_ip(row.get(\"client.ip\"))\n",
    "    rel_ips = [str(x).strip() for x in as_list(row.get(\"related.ip\")) if is_ip(str(x).strip())]\n",
    "\n",
    "    if not rel_ips:\n",
    "        return _first_ip(row.get(\"source.ip\"), row.get(\"source.address\"))\n",
    "\n",
    "    if client_ip != \"none\":\n",
    "        non_client = [ip for ip in rel_ips if ip != client_ip]\n",
    "        if non_client:\n",
    "            return non_client[-1]\n",
    "\n",
    "    return rel_ips[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbfb5aee-3bc7-4854-845f-f8ae7f94aefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_episode_folder(folder_path: Path, prefix: str, idx: int, output_dir: Path) -> None:\n",
    "    episode_id = f\"{prefix}_{idx:03d}\"\n",
    "    print(f\"\\nProcessing {folder_path.name} → {episode_id}\")\n",
    "\n",
    "    dfs = []\n",
    "    for fp in sorted(folder_path.glob(\"*.json\")):\n",
    "        print(f\"   Reading {fp.name}\")\n",
    "        df = pd.read_json(fp)\n",
    "        if \"_source\" in df.columns:\n",
    "            df = pd.json_normalize(df[\"_source\"])\n",
    "        else:\n",
    "            df = pd.json_normalize(df.to_dict(orient=\"records\"))\n",
    "        dfs.append(df)\n",
    "\n",
    "    if not dfs:\n",
    "        print(f\"   WARNING: no JSON files in {folder_path}\")\n",
    "        return\n",
    "\n",
    "    df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    df[\"episode_id\"] = episode_id\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"@timestamp\"], utc=True, errors=\"coerce\")\n",
    "\n",
    "    df[\"masked_message_cl\"] = df.apply(lambda r: build_masked_message_cl(r.to_dict()), axis=1)\n",
    "\n",
    "    df[\"stream\"] = safe_col(df, \"data_stream.dataset\").astype(str).replace({\"nan\": \"unknown_stream\", \"None\": \"unknown_stream\"})\n",
    "\n",
    "    src_ip = safe_col(df, \"source.ip\")\n",
    "    src_addr = safe_col(df, \"source.address\")\n",
    "    df[\"src_ip_anon\"] = src_ip.fillna(src_addr).astype(object).apply(short_hash)\n",
    "\n",
    "    df[\"actor_ip_anon\"] = df.apply(lambda r: extract_actor_ip(r.to_dict()), axis=1).apply(short_hash)\n",
    "\n",
    "    dst_ip = safe_col(df, \"destination.ip\")\n",
    "    dst_addr = safe_col(df, \"destination.address\")\n",
    "    df[\"dst_ip_anon\"] = dst_ip.fillna(dst_addr).astype(object).apply(short_hash)\n",
    "\n",
    "    host_col = safe_col(df, \"host.hostname\")\n",
    "    df[\"host_anon\"] = host_col.astype(object).apply(short_hash)\n",
    "\n",
    "    df[\"process_name\"] = safe_col(df, \"process.name\").astype(str)\n",
    "    df[\"ssh_method\"]   = safe_col(df, \"system.auth.ssh.method\").astype(str)\n",
    "    df[\"dport\"]        = safe_col(df, \"destination.port\").astype(str)\n",
    "\n",
    "    df[\"event_category\"] = safe_col(df, \"event.category\").apply(lambda x: join_tokens(x, default=\"\")).astype(str)\n",
    "    df[\"event_action\"]   = safe_col(df, \"event.action\").apply(lambda x: join_tokens(x, default=\"\")).astype(str)\n",
    "    df[\"event_outcome\"]  = safe_col(df, \"event.outcome\").astype(str)\n",
    "    df[\"event_code\"]     = safe_col(df, \"event.code\").astype(str)\n",
    "\n",
    "    df[\"asa_conn_id\"] = safe_col(df, \"cisco.asa.connection_id\").astype(str).replace({\"nan\": \"\", \"None\": \"\"})\n",
    "\n",
    "    for col in (\"gt_core\", \"gt_extended\"):\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].fillna(False).astype(bool)\n",
    "        else:\n",
    "            df[col] = False\n",
    "\n",
    "    final = df[[\n",
    "        \"episode_id\", \"timestamp\", \"stream\", \"process_name\", \"masked_message_cl\",\n",
    "        \"src_ip_anon\", \"actor_ip_anon\", \"dst_ip_anon\", \"host_anon\",\n",
    "        \"event_category\", \"event_action\", \"event_outcome\", \"event_code\",\n",
    "        \"dport\", \"ssh_method\", \"asa_conn_id\",\n",
    "        \"gt_core\", \"gt_extended\",\n",
    "    ]].copy()\n",
    "\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    out_path = output_dir / f\"{episode_id}.parquet\"\n",
    "    final.to_parquet(out_path, index=False)\n",
    "    print(f\"   SAVED {out_path.name} ({len(final):,} logs)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "706629c6-6b8e-40c2-bd0a-77f4680909ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Alert 1 → episode_001\n",
      "   Reading asa_alert1.json\n",
      "   Reading endpoint_events_network_alert1.json\n",
      "   Reading filebeat_alert1.json\n",
      "   Reading ise_alert1.json\n",
      "   Reading panos_alert1.json\n",
      "   Reading system_auth_sshd_alert1.json\n",
      "   Reading system_auth_sudo_systemd_alert1.json\n",
      "   Reading system_security_alert1.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"episode_id\"] = episode_id\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"timestamp\"] = pd.to_datetime(df[\"@timestamp\"], utc=True, errors=\"coerce\")\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"masked_message_cl\"] = df.apply(lambda r: build_masked_message_cl(r.to_dict()), axis=1)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"stream\"] = safe_col(df, \"data_stream.dataset\").astype(str).replace({\"nan\": \"unknown_stream\", \"None\": \"unknown_stream\"})\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"src_ip_anon\"] = src_ip.fillna(src_addr).astype(object).apply(short_hash)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"actor_ip_anon\"] = df.apply(lambda r: extract_actor_ip(r.to_dict()), axis=1).apply(short_hash)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dst_ip_anon\"] = dst_ip.fillna(dst_addr).astype(object).apply(short_hash)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"host_anon\"] = host_col.astype(object).apply(short_hash)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"process_name\"] = safe_col(df, \"process.name\").astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:47: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"ssh_method\"]   = safe_col(df, \"system.auth.ssh.method\").astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dport\"]        = safe_col(df, \"destination.port\").astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"event_category\"] = safe_col(df, \"event.category\").apply(lambda x: join_tokens(x, default=\"\")).astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"event_action\"]   = safe_col(df, \"event.action\").apply(lambda x: join_tokens(x, default=\"\")).astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"event_outcome\"]  = safe_col(df, \"event.outcome\").astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"event_code\"]     = safe_col(df, \"event.code\").astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"asa_conn_id\"] = safe_col(df, \"cisco.asa.connection_id\").astype(str).replace({\"nan\": \"\", \"None\": \"\"})\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col] = False\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col] = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SAVED episode_001.parquet (29,572 logs)\n",
      "\n",
      "Processing Alert 10 → episode_010\n",
      "   Reading asa_alert10.json\n",
      "   Reading endpoint_events_network_alert10.json\n",
      "   Reading filebeat_alert10.json\n",
      "   Reading ise_alert10.json\n",
      "   Reading panos_alert10.json\n",
      "   Reading system_auth_sshd_alert10.json\n",
      "   Reading system_auth_sudo_systemd_alert10.json\n",
      "   Reading system_security_alert10.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"episode_id\"] = episode_id\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"timestamp\"] = pd.to_datetime(df[\"@timestamp\"], utc=True, errors=\"coerce\")\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"masked_message_cl\"] = df.apply(lambda r: build_masked_message_cl(r.to_dict()), axis=1)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"stream\"] = safe_col(df, \"data_stream.dataset\").astype(str).replace({\"nan\": \"unknown_stream\", \"None\": \"unknown_stream\"})\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"src_ip_anon\"] = src_ip.fillna(src_addr).astype(object).apply(short_hash)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"actor_ip_anon\"] = df.apply(lambda r: extract_actor_ip(r.to_dict()), axis=1).apply(short_hash)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dst_ip_anon\"] = dst_ip.fillna(dst_addr).astype(object).apply(short_hash)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"host_anon\"] = host_col.astype(object).apply(short_hash)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"process_name\"] = safe_col(df, \"process.name\").astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:47: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"ssh_method\"]   = safe_col(df, \"system.auth.ssh.method\").astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dport\"]        = safe_col(df, \"destination.port\").astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"event_category\"] = safe_col(df, \"event.category\").apply(lambda x: join_tokens(x, default=\"\")).astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"event_action\"]   = safe_col(df, \"event.action\").apply(lambda x: join_tokens(x, default=\"\")).astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"event_outcome\"]  = safe_col(df, \"event.outcome\").astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"event_code\"]     = safe_col(df, \"event.code\").astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"asa_conn_id\"] = safe_col(df, \"cisco.asa.connection_id\").astype(str).replace({\"nan\": \"\", \"None\": \"\"})\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col] = False\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col] = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SAVED episode_010.parquet (29,999 logs)\n",
      "\n",
      "Processing Alert 11 → episode_011\n",
      "   Reading asa_alert11.json\n",
      "   Reading endpoint_events_network_alert11.json\n",
      "   Reading filebeat_alert11.json\n",
      "   Reading ise_alert11.json\n",
      "   Reading panos_alert11.json\n",
      "   Reading system_auth_sshd_alert11.json\n",
      "   Reading system_auth_sudo_systemd_alert11.json\n",
      "   Reading system_security_alert11.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"episode_id\"] = episode_id\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"timestamp\"] = pd.to_datetime(df[\"@timestamp\"], utc=True, errors=\"coerce\")\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"masked_message_cl\"] = df.apply(lambda r: build_masked_message_cl(r.to_dict()), axis=1)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"stream\"] = safe_col(df, \"data_stream.dataset\").astype(str).replace({\"nan\": \"unknown_stream\", \"None\": \"unknown_stream\"})\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"src_ip_anon\"] = src_ip.fillna(src_addr).astype(object).apply(short_hash)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"actor_ip_anon\"] = df.apply(lambda r: extract_actor_ip(r.to_dict()), axis=1).apply(short_hash)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dst_ip_anon\"] = dst_ip.fillna(dst_addr).astype(object).apply(short_hash)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"host_anon\"] = host_col.astype(object).apply(short_hash)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"process_name\"] = safe_col(df, \"process.name\").astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:47: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"ssh_method\"]   = safe_col(df, \"system.auth.ssh.method\").astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dport\"]        = safe_col(df, \"destination.port\").astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"event_category\"] = safe_col(df, \"event.category\").apply(lambda x: join_tokens(x, default=\"\")).astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"event_action\"]   = safe_col(df, \"event.action\").apply(lambda x: join_tokens(x, default=\"\")).astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"event_outcome\"]  = safe_col(df, \"event.outcome\").astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"event_code\"]     = safe_col(df, \"event.code\").astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"asa_conn_id\"] = safe_col(df, \"cisco.asa.connection_id\").astype(str).replace({\"nan\": \"\", \"None\": \"\"})\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col] = False\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col] = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SAVED episode_011.parquet (29,997 logs)\n",
      "\n",
      "Processing Alert 12 → episode_012\n",
      "   Reading asa_alert12.json\n",
      "   Reading endpoint_events_network_alert12.json\n",
      "   Reading filebeat_alert12.json\n",
      "   Reading ise_alert12.json\n",
      "   Reading panos_alert12.json\n",
      "   Reading system_auth_sshd_alert12.json\n",
      "   Reading system_auth_sudo_systemd_alert12.json\n",
      "   Reading system_security_alert12.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"episode_id\"] = episode_id\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"timestamp\"] = pd.to_datetime(df[\"@timestamp\"], utc=True, errors=\"coerce\")\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"masked_message_cl\"] = df.apply(lambda r: build_masked_message_cl(r.to_dict()), axis=1)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"stream\"] = safe_col(df, \"data_stream.dataset\").astype(str).replace({\"nan\": \"unknown_stream\", \"None\": \"unknown_stream\"})\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"src_ip_anon\"] = src_ip.fillna(src_addr).astype(object).apply(short_hash)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"actor_ip_anon\"] = df.apply(lambda r: extract_actor_ip(r.to_dict()), axis=1).apply(short_hash)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dst_ip_anon\"] = dst_ip.fillna(dst_addr).astype(object).apply(short_hash)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"host_anon\"] = host_col.astype(object).apply(short_hash)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"process_name\"] = safe_col(df, \"process.name\").astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:47: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"ssh_method\"]   = safe_col(df, \"system.auth.ssh.method\").astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dport\"]        = safe_col(df, \"destination.port\").astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"event_category\"] = safe_col(df, \"event.category\").apply(lambda x: join_tokens(x, default=\"\")).astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"event_action\"]   = safe_col(df, \"event.action\").apply(lambda x: join_tokens(x, default=\"\")).astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"event_outcome\"]  = safe_col(df, \"event.outcome\").astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"event_code\"]     = safe_col(df, \"event.code\").astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"asa_conn_id\"] = safe_col(df, \"cisco.asa.connection_id\").astype(str).replace({\"nan\": \"\", \"None\": \"\"})\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col] = False\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col] = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SAVED episode_012.parquet (29,998 logs)\n",
      "\n",
      "Processing Alert 13 → episode_013\n",
      "   Reading asa_alert13.json\n",
      "   Reading endpoint_events_network_alert13.json\n",
      "   Reading filebeat_alert13.json\n",
      "   Reading ise_alert13.json\n",
      "   Reading panos_alert13.json\n",
      "   Reading system_auth_sshd_alert13.json\n",
      "   Reading system_auth_sudo_systemd_alert13.json\n",
      "   Reading system_security_alert13.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"episode_id\"] = episode_id\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"timestamp\"] = pd.to_datetime(df[\"@timestamp\"], utc=True, errors=\"coerce\")\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"masked_message_cl\"] = df.apply(lambda r: build_masked_message_cl(r.to_dict()), axis=1)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"stream\"] = safe_col(df, \"data_stream.dataset\").astype(str).replace({\"nan\": \"unknown_stream\", \"None\": \"unknown_stream\"})\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"src_ip_anon\"] = src_ip.fillna(src_addr).astype(object).apply(short_hash)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"actor_ip_anon\"] = df.apply(lambda r: extract_actor_ip(r.to_dict()), axis=1).apply(short_hash)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dst_ip_anon\"] = dst_ip.fillna(dst_addr).astype(object).apply(short_hash)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"host_anon\"] = host_col.astype(object).apply(short_hash)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"process_name\"] = safe_col(df, \"process.name\").astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:47: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"ssh_method\"]   = safe_col(df, \"system.auth.ssh.method\").astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dport\"]        = safe_col(df, \"destination.port\").astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"event_category\"] = safe_col(df, \"event.category\").apply(lambda x: join_tokens(x, default=\"\")).astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"event_action\"]   = safe_col(df, \"event.action\").apply(lambda x: join_tokens(x, default=\"\")).astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"event_outcome\"]  = safe_col(df, \"event.outcome\").astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"event_code\"]     = safe_col(df, \"event.code\").astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"asa_conn_id\"] = safe_col(df, \"cisco.asa.connection_id\").astype(str).replace({\"nan\": \"\", \"None\": \"\"})\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col] = False\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col] = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SAVED episode_013.parquet (29,997 logs)\n",
      "\n",
      "Processing Alert 14 → episode_014\n",
      "   Reading asa_alert14.json\n",
      "   Reading endpoint_events_network_alert14.json\n",
      "   Reading filebeat_alert14.json\n",
      "   Reading ise_alert14.json\n",
      "   Reading panos_alert7.json\n",
      "   Reading system_auth_sshd_alert14.json\n",
      "   Reading system_auth_sudo_systemd_alert14.json\n",
      "   Reading system_security_alert14.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"episode_id\"] = episode_id\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"timestamp\"] = pd.to_datetime(df[\"@timestamp\"], utc=True, errors=\"coerce\")\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"masked_message_cl\"] = df.apply(lambda r: build_masked_message_cl(r.to_dict()), axis=1)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"stream\"] = safe_col(df, \"data_stream.dataset\").astype(str).replace({\"nan\": \"unknown_stream\", \"None\": \"unknown_stream\"})\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"src_ip_anon\"] = src_ip.fillna(src_addr).astype(object).apply(short_hash)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"actor_ip_anon\"] = df.apply(lambda r: extract_actor_ip(r.to_dict()), axis=1).apply(short_hash)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dst_ip_anon\"] = dst_ip.fillna(dst_addr).astype(object).apply(short_hash)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"host_anon\"] = host_col.astype(object).apply(short_hash)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"process_name\"] = safe_col(df, \"process.name\").astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:47: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"ssh_method\"]   = safe_col(df, \"system.auth.ssh.method\").astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dport\"]        = safe_col(df, \"destination.port\").astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"event_category\"] = safe_col(df, \"event.category\").apply(lambda x: join_tokens(x, default=\"\")).astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"event_action\"]   = safe_col(df, \"event.action\").apply(lambda x: join_tokens(x, default=\"\")).astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"event_outcome\"]  = safe_col(df, \"event.outcome\").astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"event_code\"]     = safe_col(df, \"event.code\").astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"asa_conn_id\"] = safe_col(df, \"cisco.asa.connection_id\").astype(str).replace({\"nan\": \"\", \"None\": \"\"})\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col] = False\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col] = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SAVED episode_014.parquet (30,327 logs)\n",
      "\n",
      "Processing Alert 15 → episode_015\n",
      "   Reading asa_alert15.json\n",
      "   Reading endpoint_events_network_alert15.json\n",
      "   Reading filebeat_alert15.json\n",
      "   Reading ise_alert15.json\n",
      "   Reading panos_alert15.json\n",
      "   Reading system_auth_sshd_alert15.json\n",
      "   Reading system_auth_sudo_systemd_alert15.json\n",
      "   Reading system_security_alert15.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"episode_id\"] = episode_id\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"timestamp\"] = pd.to_datetime(df[\"@timestamp\"], utc=True, errors=\"coerce\")\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"masked_message_cl\"] = df.apply(lambda r: build_masked_message_cl(r.to_dict()), axis=1)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"stream\"] = safe_col(df, \"data_stream.dataset\").astype(str).replace({\"nan\": \"unknown_stream\", \"None\": \"unknown_stream\"})\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"src_ip_anon\"] = src_ip.fillna(src_addr).astype(object).apply(short_hash)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"actor_ip_anon\"] = df.apply(lambda r: extract_actor_ip(r.to_dict()), axis=1).apply(short_hash)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dst_ip_anon\"] = dst_ip.fillna(dst_addr).astype(object).apply(short_hash)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"host_anon\"] = host_col.astype(object).apply(short_hash)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"process_name\"] = safe_col(df, \"process.name\").astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:47: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"ssh_method\"]   = safe_col(df, \"system.auth.ssh.method\").astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dport\"]        = safe_col(df, \"destination.port\").astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"event_category\"] = safe_col(df, \"event.category\").apply(lambda x: join_tokens(x, default=\"\")).astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"event_action\"]   = safe_col(df, \"event.action\").apply(lambda x: join_tokens(x, default=\"\")).astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"event_outcome\"]  = safe_col(df, \"event.outcome\").astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"event_code\"]     = safe_col(df, \"event.code\").astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"asa_conn_id\"] = safe_col(df, \"cisco.asa.connection_id\").astype(str).replace({\"nan\": \"\", \"None\": \"\"})\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col] = False\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col] = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SAVED episode_015.parquet (30,000 logs)\n",
      "\n",
      "Processing Alert 2 → episode_002\n",
      "   Reading asa_alert2.json\n",
      "   Reading endpoint_events_network_alert2.json\n",
      "   Reading filebeat_alert2.json\n",
      "   Reading ise_alert2.json\n",
      "   Reading panos_alert2.json\n",
      "   Reading system_auth_sshd_alert2.json\n",
      "   Reading system_auth_sudo_systemd_alert2.json\n",
      "   Reading system_security_alert2.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"episode_id\"] = episode_id\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"timestamp\"] = pd.to_datetime(df[\"@timestamp\"], utc=True, errors=\"coerce\")\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"masked_message_cl\"] = df.apply(lambda r: build_masked_message_cl(r.to_dict()), axis=1)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"stream\"] = safe_col(df, \"data_stream.dataset\").astype(str).replace({\"nan\": \"unknown_stream\", \"None\": \"unknown_stream\"})\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"src_ip_anon\"] = src_ip.fillna(src_addr).astype(object).apply(short_hash)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"actor_ip_anon\"] = df.apply(lambda r: extract_actor_ip(r.to_dict()), axis=1).apply(short_hash)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dst_ip_anon\"] = dst_ip.fillna(dst_addr).astype(object).apply(short_hash)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"host_anon\"] = host_col.astype(object).apply(short_hash)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"process_name\"] = safe_col(df, \"process.name\").astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:47: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"ssh_method\"]   = safe_col(df, \"system.auth.ssh.method\").astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dport\"]        = safe_col(df, \"destination.port\").astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"event_category\"] = safe_col(df, \"event.category\").apply(lambda x: join_tokens(x, default=\"\")).astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"event_action\"]   = safe_col(df, \"event.action\").apply(lambda x: join_tokens(x, default=\"\")).astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"event_outcome\"]  = safe_col(df, \"event.outcome\").astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"event_code\"]     = safe_col(df, \"event.code\").astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"asa_conn_id\"] = safe_col(df, \"cisco.asa.connection_id\").astype(str).replace({\"nan\": \"\", \"None\": \"\"})\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col] = False\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col] = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SAVED episode_002.parquet (29,997 logs)\n",
      "\n",
      "Processing Alert 3 → episode_003\n",
      "   Reading asa_alert3.json\n",
      "   Reading endpoint_events_network_alert3.json\n",
      "   Reading filebeat_alert3.json\n",
      "   Reading ise_alert3.json\n",
      "   Reading panos_alert3.json\n",
      "   Reading system_auth_sshd_alert3.json\n",
      "   Reading system_auth_sudo_systemd_alert3.json\n",
      "   Reading system_security_alert3.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"episode_id\"] = episode_id\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"timestamp\"] = pd.to_datetime(df[\"@timestamp\"], utc=True, errors=\"coerce\")\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"masked_message_cl\"] = df.apply(lambda r: build_masked_message_cl(r.to_dict()), axis=1)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"stream\"] = safe_col(df, \"data_stream.dataset\").astype(str).replace({\"nan\": \"unknown_stream\", \"None\": \"unknown_stream\"})\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"src_ip_anon\"] = src_ip.fillna(src_addr).astype(object).apply(short_hash)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"actor_ip_anon\"] = df.apply(lambda r: extract_actor_ip(r.to_dict()), axis=1).apply(short_hash)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dst_ip_anon\"] = dst_ip.fillna(dst_addr).astype(object).apply(short_hash)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"host_anon\"] = host_col.astype(object).apply(short_hash)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"process_name\"] = safe_col(df, \"process.name\").astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:47: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"ssh_method\"]   = safe_col(df, \"system.auth.ssh.method\").astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dport\"]        = safe_col(df, \"destination.port\").astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"event_category\"] = safe_col(df, \"event.category\").apply(lambda x: join_tokens(x, default=\"\")).astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"event_action\"]   = safe_col(df, \"event.action\").apply(lambda x: join_tokens(x, default=\"\")).astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"event_outcome\"]  = safe_col(df, \"event.outcome\").astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"event_code\"]     = safe_col(df, \"event.code\").astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"asa_conn_id\"] = safe_col(df, \"cisco.asa.connection_id\").astype(str).replace({\"nan\": \"\", \"None\": \"\"})\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col] = False\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col] = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SAVED episode_003.parquet (30,000 logs)\n",
      "\n",
      "Processing Alert 4 → episode_004\n",
      "   Reading asa_alert4.json\n",
      "   Reading endpoint_events_network_alert4.json\n",
      "   Reading filebeat_alert4.json\n",
      "   Reading ise_alert4.json\n",
      "   Reading panos_alert4.json\n",
      "   Reading system_auth_sshd_alert4.json\n",
      "   Reading system_auth_sudo_systemd_alert4.json\n",
      "   Reading system_security_alert4.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"episode_id\"] = episode_id\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"timestamp\"] = pd.to_datetime(df[\"@timestamp\"], utc=True, errors=\"coerce\")\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"masked_message_cl\"] = df.apply(lambda r: build_masked_message_cl(r.to_dict()), axis=1)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"stream\"] = safe_col(df, \"data_stream.dataset\").astype(str).replace({\"nan\": \"unknown_stream\", \"None\": \"unknown_stream\"})\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"src_ip_anon\"] = src_ip.fillna(src_addr).astype(object).apply(short_hash)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"actor_ip_anon\"] = df.apply(lambda r: extract_actor_ip(r.to_dict()), axis=1).apply(short_hash)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dst_ip_anon\"] = dst_ip.fillna(dst_addr).astype(object).apply(short_hash)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"host_anon\"] = host_col.astype(object).apply(short_hash)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"process_name\"] = safe_col(df, \"process.name\").astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:47: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"ssh_method\"]   = safe_col(df, \"system.auth.ssh.method\").astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dport\"]        = safe_col(df, \"destination.port\").astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"event_category\"] = safe_col(df, \"event.category\").apply(lambda x: join_tokens(x, default=\"\")).astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"event_action\"]   = safe_col(df, \"event.action\").apply(lambda x: join_tokens(x, default=\"\")).astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"event_outcome\"]  = safe_col(df, \"event.outcome\").astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"event_code\"]     = safe_col(df, \"event.code\").astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"asa_conn_id\"] = safe_col(df, \"cisco.asa.connection_id\").astype(str).replace({\"nan\": \"\", \"None\": \"\"})\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col] = False\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col] = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SAVED episode_004.parquet (29,999 logs)\n",
      "\n",
      "Processing Alert 5 → episode_005\n",
      "   Reading asa_alert5.json\n",
      "   Reading endpoint_events_network_alert5.json\n",
      "   Reading filebeat_alert5.json\n",
      "   Reading ise_alert5.json\n",
      "   Reading panos_alert5.json\n",
      "   Reading system_auth_sshd_alert5.json\n",
      "   Reading system_auth_sudo_systemd_alert5.json\n",
      "   Reading system_security_alert5.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"episode_id\"] = episode_id\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"timestamp\"] = pd.to_datetime(df[\"@timestamp\"], utc=True, errors=\"coerce\")\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"masked_message_cl\"] = df.apply(lambda r: build_masked_message_cl(r.to_dict()), axis=1)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"stream\"] = safe_col(df, \"data_stream.dataset\").astype(str).replace({\"nan\": \"unknown_stream\", \"None\": \"unknown_stream\"})\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"src_ip_anon\"] = src_ip.fillna(src_addr).astype(object).apply(short_hash)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"actor_ip_anon\"] = df.apply(lambda r: extract_actor_ip(r.to_dict()), axis=1).apply(short_hash)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dst_ip_anon\"] = dst_ip.fillna(dst_addr).astype(object).apply(short_hash)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"host_anon\"] = host_col.astype(object).apply(short_hash)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"process_name\"] = safe_col(df, \"process.name\").astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:47: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"ssh_method\"]   = safe_col(df, \"system.auth.ssh.method\").astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dport\"]        = safe_col(df, \"destination.port\").astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"event_category\"] = safe_col(df, \"event.category\").apply(lambda x: join_tokens(x, default=\"\")).astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"event_action\"]   = safe_col(df, \"event.action\").apply(lambda x: join_tokens(x, default=\"\")).astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"event_outcome\"]  = safe_col(df, \"event.outcome\").astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"event_code\"]     = safe_col(df, \"event.code\").astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"asa_conn_id\"] = safe_col(df, \"cisco.asa.connection_id\").astype(str).replace({\"nan\": \"\", \"None\": \"\"})\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col] = False\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col] = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SAVED episode_005.parquet (29,998 logs)\n",
      "\n",
      "Processing Alert 6 → episode_006\n",
      "   Reading asa_alert6.json\n",
      "   Reading endpoint_events_network_alert6.json\n",
      "   Reading filebeat_alert6.json\n",
      "   Reading ise_alert6.json\n",
      "   Reading panos_alert6.json\n",
      "   Reading system_auth_sshd_alert6.json\n",
      "   Reading system_auth_sudo_systemd_alert6.json\n",
      "   Reading system_security_alert6.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"episode_id\"] = episode_id\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"timestamp\"] = pd.to_datetime(df[\"@timestamp\"], utc=True, errors=\"coerce\")\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"masked_message_cl\"] = df.apply(lambda r: build_masked_message_cl(r.to_dict()), axis=1)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"stream\"] = safe_col(df, \"data_stream.dataset\").astype(str).replace({\"nan\": \"unknown_stream\", \"None\": \"unknown_stream\"})\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"src_ip_anon\"] = src_ip.fillna(src_addr).astype(object).apply(short_hash)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"actor_ip_anon\"] = df.apply(lambda r: extract_actor_ip(r.to_dict()), axis=1).apply(short_hash)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dst_ip_anon\"] = dst_ip.fillna(dst_addr).astype(object).apply(short_hash)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"host_anon\"] = host_col.astype(object).apply(short_hash)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"process_name\"] = safe_col(df, \"process.name\").astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:47: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"ssh_method\"]   = safe_col(df, \"system.auth.ssh.method\").astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dport\"]        = safe_col(df, \"destination.port\").astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"event_category\"] = safe_col(df, \"event.category\").apply(lambda x: join_tokens(x, default=\"\")).astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"event_action\"]   = safe_col(df, \"event.action\").apply(lambda x: join_tokens(x, default=\"\")).astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"event_outcome\"]  = safe_col(df, \"event.outcome\").astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"event_code\"]     = safe_col(df, \"event.code\").astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"asa_conn_id\"] = safe_col(df, \"cisco.asa.connection_id\").astype(str).replace({\"nan\": \"\", \"None\": \"\"})\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col] = False\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col] = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SAVED episode_006.parquet (29,997 logs)\n",
      "\n",
      "Processing Alert 7 → episode_007\n",
      "   Reading asa_alert7.json\n",
      "   Reading endpoint_events_network_alert7.json\n",
      "   Reading filebeat_alert7.json\n",
      "   Reading ise_alert7.json\n",
      "   Reading panos_alert7.json\n",
      "   Reading system_auth_sshd_alert7.json\n",
      "   Reading system_auth_sudo_systemd_alert7.json\n",
      "   Reading system_security_alert7.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"episode_id\"] = episode_id\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"timestamp\"] = pd.to_datetime(df[\"@timestamp\"], utc=True, errors=\"coerce\")\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"masked_message_cl\"] = df.apply(lambda r: build_masked_message_cl(r.to_dict()), axis=1)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"stream\"] = safe_col(df, \"data_stream.dataset\").astype(str).replace({\"nan\": \"unknown_stream\", \"None\": \"unknown_stream\"})\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"src_ip_anon\"] = src_ip.fillna(src_addr).astype(object).apply(short_hash)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"actor_ip_anon\"] = df.apply(lambda r: extract_actor_ip(r.to_dict()), axis=1).apply(short_hash)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dst_ip_anon\"] = dst_ip.fillna(dst_addr).astype(object).apply(short_hash)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"host_anon\"] = host_col.astype(object).apply(short_hash)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"process_name\"] = safe_col(df, \"process.name\").astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:47: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"ssh_method\"]   = safe_col(df, \"system.auth.ssh.method\").astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dport\"]        = safe_col(df, \"destination.port\").astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"event_category\"] = safe_col(df, \"event.category\").apply(lambda x: join_tokens(x, default=\"\")).astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"event_action\"]   = safe_col(df, \"event.action\").apply(lambda x: join_tokens(x, default=\"\")).astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"event_outcome\"]  = safe_col(df, \"event.outcome\").astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"event_code\"]     = safe_col(df, \"event.code\").astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"asa_conn_id\"] = safe_col(df, \"cisco.asa.connection_id\").astype(str).replace({\"nan\": \"\", \"None\": \"\"})\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col] = False\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col] = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SAVED episode_007.parquet (29,999 logs)\n",
      "\n",
      "Processing Alert 8 → episode_008\n",
      "   Reading asa_alert8.json\n",
      "   Reading endpoint_events_network_alert8.json\n",
      "   Reading filebeat_alert8.json\n",
      "   Reading ise_alert8.json\n",
      "   Reading panos_alert8.json\n",
      "   Reading system_auth_sshd_alert8.json\n",
      "   Reading system_auth_sudo_systemd_alert8.json\n",
      "   Reading system_security_alert8.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"episode_id\"] = episode_id\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"timestamp\"] = pd.to_datetime(df[\"@timestamp\"], utc=True, errors=\"coerce\")\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"masked_message_cl\"] = df.apply(lambda r: build_masked_message_cl(r.to_dict()), axis=1)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"stream\"] = safe_col(df, \"data_stream.dataset\").astype(str).replace({\"nan\": \"unknown_stream\", \"None\": \"unknown_stream\"})\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"src_ip_anon\"] = src_ip.fillna(src_addr).astype(object).apply(short_hash)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"actor_ip_anon\"] = df.apply(lambda r: extract_actor_ip(r.to_dict()), axis=1).apply(short_hash)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dst_ip_anon\"] = dst_ip.fillna(dst_addr).astype(object).apply(short_hash)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"host_anon\"] = host_col.astype(object).apply(short_hash)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"process_name\"] = safe_col(df, \"process.name\").astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:47: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"ssh_method\"]   = safe_col(df, \"system.auth.ssh.method\").astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dport\"]        = safe_col(df, \"destination.port\").astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"event_category\"] = safe_col(df, \"event.category\").apply(lambda x: join_tokens(x, default=\"\")).astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"event_action\"]   = safe_col(df, \"event.action\").apply(lambda x: join_tokens(x, default=\"\")).astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"event_outcome\"]  = safe_col(df, \"event.outcome\").astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"event_code\"]     = safe_col(df, \"event.code\").astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"asa_conn_id\"] = safe_col(df, \"cisco.asa.connection_id\").astype(str).replace({\"nan\": \"\", \"None\": \"\"})\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col] = False\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col] = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SAVED episode_008.parquet (29,998 logs)\n",
      "\n",
      "Processing Alert 9 → episode_009\n",
      "   Reading asa_alert9.json\n",
      "   Reading endpoint_events_network_alert9.json\n",
      "   Reading filebeat_alert9.json\n",
      "   Reading ise_alert9.json\n",
      "   Reading panos_alert9.json\n",
      "   Reading system_auth_sshd_alert9.json\n",
      "   Reading system_auth_sudo_systemd_alert9.json\n",
      "   Reading system_security_alert9.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"episode_id\"] = episode_id\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"timestamp\"] = pd.to_datetime(df[\"@timestamp\"], utc=True, errors=\"coerce\")\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"masked_message_cl\"] = df.apply(lambda r: build_masked_message_cl(r.to_dict()), axis=1)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"stream\"] = safe_col(df, \"data_stream.dataset\").astype(str).replace({\"nan\": \"unknown_stream\", \"None\": \"unknown_stream\"})\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"src_ip_anon\"] = src_ip.fillna(src_addr).astype(object).apply(short_hash)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"actor_ip_anon\"] = df.apply(lambda r: extract_actor_ip(r.to_dict()), axis=1).apply(short_hash)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dst_ip_anon\"] = dst_ip.fillna(dst_addr).astype(object).apply(short_hash)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"host_anon\"] = host_col.astype(object).apply(short_hash)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"process_name\"] = safe_col(df, \"process.name\").astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:47: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"ssh_method\"]   = safe_col(df, \"system.auth.ssh.method\").astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dport\"]        = safe_col(df, \"destination.port\").astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"event_category\"] = safe_col(df, \"event.category\").apply(lambda x: join_tokens(x, default=\"\")).astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"event_action\"]   = safe_col(df, \"event.action\").apply(lambda x: join_tokens(x, default=\"\")).astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"event_outcome\"]  = safe_col(df, \"event.outcome\").astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"event_code\"]     = safe_col(df, \"event.code\").astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"asa_conn_id\"] = safe_col(df, \"cisco.asa.connection_id\").astype(str).replace({\"nan\": \"\", \"None\": \"\"})\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col] = False\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col] = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SAVED episode_009.parquet (30,000 logs)\n",
      "\n",
      "Processing Background 1 → background_001\n",
      "   Reading asa_alert16.json\n",
      "   Reading endpoint_events_network_alert16.json\n",
      "   Reading filebeat_alert16.json\n",
      "   Reading ise_alert16.json\n",
      "   Reading panos_alert16.json\n",
      "   Reading system_auth_sshd_alert16.json\n",
      "   Reading system_auth_sudo_systemd_alert16.json\n",
      "   Reading system_security_alert16.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"episode_id\"] = episode_id\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"timestamp\"] = pd.to_datetime(df[\"@timestamp\"], utc=True, errors=\"coerce\")\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"masked_message_cl\"] = df.apply(lambda r: build_masked_message_cl(r.to_dict()), axis=1)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"stream\"] = safe_col(df, \"data_stream.dataset\").astype(str).replace({\"nan\": \"unknown_stream\", \"None\": \"unknown_stream\"})\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"src_ip_anon\"] = src_ip.fillna(src_addr).astype(object).apply(short_hash)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"actor_ip_anon\"] = df.apply(lambda r: extract_actor_ip(r.to_dict()), axis=1).apply(short_hash)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dst_ip_anon\"] = dst_ip.fillna(dst_addr).astype(object).apply(short_hash)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"host_anon\"] = host_col.astype(object).apply(short_hash)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"process_name\"] = safe_col(df, \"process.name\").astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:47: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"ssh_method\"]   = safe_col(df, \"system.auth.ssh.method\").astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dport\"]        = safe_col(df, \"destination.port\").astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"event_category\"] = safe_col(df, \"event.category\").apply(lambda x: join_tokens(x, default=\"\")).astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"event_action\"]   = safe_col(df, \"event.action\").apply(lambda x: join_tokens(x, default=\"\")).astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"event_outcome\"]  = safe_col(df, \"event.outcome\").astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"event_code\"]     = safe_col(df, \"event.code\").astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"asa_conn_id\"] = safe_col(df, \"cisco.asa.connection_id\").astype(str).replace({\"nan\": \"\", \"None\": \"\"})\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col] = False\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col] = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SAVED background_001.parquet (30,000 logs)\n",
      "\n",
      "Processing Background 2 → background_002\n",
      "   Reading asa_alert17.json\n",
      "   Reading endpoint_events_network_alert17.json\n",
      "   Reading filebeat_alert17.json\n",
      "   Reading ise_alert17.json\n",
      "   Reading panos_alert17.json\n",
      "   Reading system_auth_sshd_alert17.json\n",
      "   Reading system_auth_sudo_systemd_alert17.json\n",
      "   Reading system_security_alert17.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"episode_id\"] = episode_id\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"timestamp\"] = pd.to_datetime(df[\"@timestamp\"], utc=True, errors=\"coerce\")\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"masked_message_cl\"] = df.apply(lambda r: build_masked_message_cl(r.to_dict()), axis=1)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"stream\"] = safe_col(df, \"data_stream.dataset\").astype(str).replace({\"nan\": \"unknown_stream\", \"None\": \"unknown_stream\"})\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"src_ip_anon\"] = src_ip.fillna(src_addr).astype(object).apply(short_hash)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"actor_ip_anon\"] = df.apply(lambda r: extract_actor_ip(r.to_dict()), axis=1).apply(short_hash)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dst_ip_anon\"] = dst_ip.fillna(dst_addr).astype(object).apply(short_hash)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"host_anon\"] = host_col.astype(object).apply(short_hash)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"process_name\"] = safe_col(df, \"process.name\").astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:47: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"ssh_method\"]   = safe_col(df, \"system.auth.ssh.method\").astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dport\"]        = safe_col(df, \"destination.port\").astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"event_category\"] = safe_col(df, \"event.category\").apply(lambda x: join_tokens(x, default=\"\")).astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"event_action\"]   = safe_col(df, \"event.action\").apply(lambda x: join_tokens(x, default=\"\")).astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"event_outcome\"]  = safe_col(df, \"event.outcome\").astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"event_code\"]     = safe_col(df, \"event.code\").astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"asa_conn_id\"] = safe_col(df, \"cisco.asa.connection_id\").astype(str).replace({\"nan\": \"\", \"None\": \"\"})\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col] = False\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col] = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SAVED background_002.parquet (30,000 logs)\n",
      "\n",
      "Processing Background 3 → background_003\n",
      "   Reading asa_alert18.json\n",
      "   Reading endpoint_events_network_alert18.json\n",
      "   Reading filebeat_alert18.json\n",
      "   Reading ise_alert18.json\n",
      "   Reading panos_alert18.json\n",
      "   Reading system_auth_sshd_alert18.json\n",
      "   Reading system_auth_sudo_systemd_alert18.json\n",
      "   Reading system_security_alert18.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"episode_id\"] = episode_id\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"timestamp\"] = pd.to_datetime(df[\"@timestamp\"], utc=True, errors=\"coerce\")\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"masked_message_cl\"] = df.apply(lambda r: build_masked_message_cl(r.to_dict()), axis=1)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"stream\"] = safe_col(df, \"data_stream.dataset\").astype(str).replace({\"nan\": \"unknown_stream\", \"None\": \"unknown_stream\"})\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"src_ip_anon\"] = src_ip.fillna(src_addr).astype(object).apply(short_hash)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"actor_ip_anon\"] = df.apply(lambda r: extract_actor_ip(r.to_dict()), axis=1).apply(short_hash)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dst_ip_anon\"] = dst_ip.fillna(dst_addr).astype(object).apply(short_hash)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"host_anon\"] = host_col.astype(object).apply(short_hash)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"process_name\"] = safe_col(df, \"process.name\").astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:47: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"ssh_method\"]   = safe_col(df, \"system.auth.ssh.method\").astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dport\"]        = safe_col(df, \"destination.port\").astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"event_category\"] = safe_col(df, \"event.category\").apply(lambda x: join_tokens(x, default=\"\")).astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"event_action\"]   = safe_col(df, \"event.action\").apply(lambda x: join_tokens(x, default=\"\")).astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"event_outcome\"]  = safe_col(df, \"event.outcome\").astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"event_code\"]     = safe_col(df, \"event.code\").astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"asa_conn_id\"] = safe_col(df, \"cisco.asa.connection_id\").astype(str).replace({\"nan\": \"\", \"None\": \"\"})\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col] = False\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col] = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SAVED background_003.parquet (29,927 logs)\n",
      "\n",
      "ALERT + BACKGROUND EPISODES READY\n"
     ]
    }
   ],
   "source": [
    "# ALERT EPISODES\n",
    "alert_folders = sorted([p for p in PROJECT_DIR.iterdir() if p.is_dir() and p.name.startswith(\"Alert \")])\n",
    "for folder in alert_folders:\n",
    "    episode_num = int(folder.name.split()[-1])\n",
    "    process_episode_folder(folder, prefix=\"episode\", idx=episode_num, output_dir=OUTPUT_DIR)\n",
    "\n",
    "# BACKGROUND EPISODES\n",
    "bg_folders = sorted([p for p in PROJECT_DIR.iterdir() if p.is_dir() and p.name.startswith(\"Background \")])\n",
    "for i, folder in enumerate(bg_folders, start=1):\n",
    "    process_episode_folder(folder, prefix=\"background\", idx=i, output_dir=OUTPUT_DIR)\n",
    "\n",
    "print(\"\\nALERT + BACKGROUND EPISODES READY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "252d8c21-710c-440a-9c30-37231883d9ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Golden → episode_016\n",
      "   Reading asa_golden.json\n",
      "   Reading endpoint_events_network_golden.json\n",
      "   Reading filebeat_golden.json\n",
      "   Reading ise_attacker_golden.json\n",
      "   Reading ise_rest_golden.json\n",
      "   Reading panos_attacker_golden.json\n",
      "   Reading panos_rest_golden.json\n",
      "   Reading system_auth_sshd_attacker_golden.json\n",
      "   Reading system_auth_sshd_rest_golden.json\n",
      "   Reading system_auth_sudo_systemd_golden.json\n",
      "   Reading system_security_attacker_golden.json\n",
      "   Reading system_security_rest_golden.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"episode_id\"] = episode_id\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"timestamp\"] = pd.to_datetime(df[\"@timestamp\"], utc=True, errors=\"coerce\")\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"masked_message_cl\"] = df.apply(lambda r: build_masked_message_cl(r.to_dict()), axis=1)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"stream\"] = safe_col(df, \"data_stream.dataset\").astype(str).replace({\"nan\": \"unknown_stream\", \"None\": \"unknown_stream\"})\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"src_ip_anon\"] = src_ip.fillna(src_addr).astype(object).apply(short_hash)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"actor_ip_anon\"] = df.apply(lambda r: extract_actor_ip(r.to_dict()), axis=1).apply(short_hash)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dst_ip_anon\"] = dst_ip.fillna(dst_addr).astype(object).apply(short_hash)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"host_anon\"] = host_col.astype(object).apply(short_hash)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"process_name\"] = safe_col(df, \"process.name\").astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:47: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"ssh_method\"]   = safe_col(df, \"system.auth.ssh.method\").astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dport\"]        = safe_col(df, \"destination.port\").astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"event_category\"] = safe_col(df, \"event.category\").apply(lambda x: join_tokens(x, default=\"\")).astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"event_action\"]   = safe_col(df, \"event.action\").apply(lambda x: join_tokens(x, default=\"\")).astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"event_outcome\"]  = safe_col(df, \"event.outcome\").astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"event_code\"]     = safe_col(df, \"event.code\").astype(str)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"asa_conn_id\"] = safe_col(df, \"cisco.asa.connection_id\").astype(str).replace({\"nan\": \"\", \"None\": \"\"})\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:59: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col] = df[col].fillna(False).astype(bool)\n",
      "C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_40840\\3572390707.py:59: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col] = df[col].fillna(False).astype(bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SAVED episode_016.parquet (29,998 logs)\n"
     ]
    }
   ],
   "source": [
    "# GOLDEN EPISODE\n",
    "golden_folder = sorted([p for p in PROJECT_DIR.iterdir() if p.is_dir() and p.name.startswith(\"Golden\")])\n",
    "for folder in golden_folder:\n",
    "    episode_num = 16\n",
    "    process_episode_folder(folder, prefix=\"episode\", idx=episode_num, output_dir=OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13c71f78-e105-4f5b-b926-d8ff40ce1027",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = sorted(OUTPUT_DIR.glob(\"*.parquet\"))\n",
    "dfs = [pd.read_parquet(f) for f in all_files]\n",
    "episodes_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "def episode_type(eid: str, golden_id: str) -> str:\n",
    "    if eid == golden_id:\n",
    "        return \"golden\"\n",
    "    if eid.startswith(\"episode_\"):\n",
    "        return \"alert\"\n",
    "    if eid.startswith(\"background_\"):\n",
    "        return \"background\"\n",
    "    return \"unknown\"\n",
    "\n",
    "def bucket_dport(val: str) -> str:\n",
    "    val = str(val).split(\".\")[0]\n",
    "    if val in (\"22\", \"2222\"):\n",
    "        return \"ssh\"\n",
    "    if val in (\"\", \"nan\", \"None\"):\n",
    "        return \"unknown\"\n",
    "    return \"other\"\n",
    "\n",
    "episodes_df[\"episode_type\"] = episodes_df[\"episode_id\"].astype(str).apply(lambda x: episode_type(x, cfg.golden_id))\n",
    "\n",
    "episodes_df[\"dport_bucket\"] = episodes_df.get(\"dport\", \"\").astype(str).apply(bucket_dport)\n",
    "episodes_df[\"event_outcome_norm\"] = (\n",
    "    episodes_df.get(\"event_outcome\", \"\")\n",
    "    .astype(str)\n",
    "    .str.lower()\n",
    "    .replace({\"nan\": \"\", \"none\": \"\"})\n",
    ")\n",
    "episodes_df[\"stream\"] = episodes_df[\"stream\"].astype(str).replace({\"nan\": \"unknown_stream\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c74f961-be09-4b66-99fd-011df4d8a380",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_evidence_id(df: pd.DataFrame, cfg) -> pd.Series:\n",
    "    df = df.copy()\n",
    "\n",
    "    evidence = pd.Series(\"row_\" + df.index.astype(str), index=df.index)\n",
    "\n",
    "    mask = df[\"stream\"].isin(cfg.duplicate_prone_streams)\n",
    "\n",
    "    asa_mask = mask & (df[\"stream\"] == \"cisco_asa.log\")\n",
    "    if asa_mask.any():\n",
    "        cols = [\n",
    "            \"timestamp\", \"stream\",\n",
    "            \"asa_conn_id\",              \n",
    "            \"src_ip_anon\", \"dst_ip_anon\", \"host_anon\",\n",
    "            \"event_action\", \"event_outcome\", \"event_code\",\n",
    "            \"dport\",\n",
    "        ]\n",
    "        use = [c for c in cols if c in df.columns]\n",
    "        key = df.loc[asa_mask, use].fillna(\"\").astype(str).agg(\"|\".join, axis=1)\n",
    "        sig = key.map(lambda s: hashlib.sha256(s.encode(\"utf-8\")).hexdigest()[: cfg.evidence_hash_len])\n",
    "        evidence.loc[asa_mask] = sig\n",
    "\n",
    "    ise_mask = mask & (df[\"stream\"] == \"cisco_ise.log\")\n",
    "    if ise_mask.any():\n",
    "        cols = [\n",
    "            \"timestamp\", \"stream\", \"masked_message_cl\",\n",
    "            \"src_ip_anon\", \"dst_ip_anon\", \"host_anon\",\n",
    "            \"event_action\", \"event_outcome\", \"event_code\",\n",
    "            \"dport\",\n",
    "        ]\n",
    "        use = [c for c in cols if c in df.columns]\n",
    "        key = df.loc[ise_mask, use].fillna(\"\").astype(str).agg(\"|\".join, axis=1)\n",
    "        sig = key.map(lambda s: hashlib.sha256(s.encode(\"utf-8\")).hexdigest()[: cfg.evidence_hash_len])\n",
    "        evidence.loc[ise_mask] = sig\n",
    "\n",
    "    return evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1c6ed5b-29d1-4d8f-93b3-6115979968bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "episodes_df[\"evidence_id\"] = make_evidence_id(episodes_df, cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c24576e-200b-48f1-b057-4a83d03bd8de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episode_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>stream</th>\n",
       "      <th>process_name</th>\n",
       "      <th>masked_message_cl</th>\n",
       "      <th>src_ip_anon</th>\n",
       "      <th>actor_ip_anon</th>\n",
       "      <th>dst_ip_anon</th>\n",
       "      <th>host_anon</th>\n",
       "      <th>event_category</th>\n",
       "      <th>...</th>\n",
       "      <th>event_code</th>\n",
       "      <th>dport</th>\n",
       "      <th>ssh_method</th>\n",
       "      <th>asa_conn_id</th>\n",
       "      <th>gt_core</th>\n",
       "      <th>gt_extended</th>\n",
       "      <th>episode_type</th>\n",
       "      <th>dport_bucket</th>\n",
       "      <th>event_outcome_norm</th>\n",
       "      <th>evidence_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>background_001</td>\n",
       "      <td>2025-09-25 22:00:00.494000+00:00</td>\n",
       "      <td>cisco_asa.log</td>\n",
       "      <td>nan</td>\n",
       "      <td>[cisco_asa.log] kind=event type=connection+end...</td>\n",
       "      <td>5644b8637bd0</td>\n",
       "      <td>5644b8637bd0</td>\n",
       "      <td>1cd7d76ee854</td>\n",
       "      <td>485661e4763f</td>\n",
       "      <td>network</td>\n",
       "      <td>...</td>\n",
       "      <td>302014</td>\n",
       "      <td>22.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>4964540</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>background</td>\n",
       "      <td>ssh</td>\n",
       "      <td></td>\n",
       "      <td>922626fa84d0f2d0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>background_001</td>\n",
       "      <td>2025-09-25 22:00:02.065000+00:00</td>\n",
       "      <td>cisco_asa.log</td>\n",
       "      <td>nan</td>\n",
       "      <td>[cisco_asa.log] kind=event type=connection+sta...</td>\n",
       "      <td>3ae69698411f</td>\n",
       "      <td>3ae69698411f</td>\n",
       "      <td>613457f360a8</td>\n",
       "      <td>d25837bc88b6</td>\n",
       "      <td>network</td>\n",
       "      <td>...</td>\n",
       "      <td>302013</td>\n",
       "      <td>22.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>2793740973</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>background</td>\n",
       "      <td>ssh</td>\n",
       "      <td>success</td>\n",
       "      <td>e152cd0486f94fee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>background_001</td>\n",
       "      <td>2025-09-25 22:00:02.576000+00:00</td>\n",
       "      <td>cisco_asa.log</td>\n",
       "      <td>nan</td>\n",
       "      <td>[cisco_asa.log] kind=event type=connection+sta...</td>\n",
       "      <td>3ae69698411f</td>\n",
       "      <td>3ae69698411f</td>\n",
       "      <td>613457f360a8</td>\n",
       "      <td>d25837bc88b6</td>\n",
       "      <td>network</td>\n",
       "      <td>...</td>\n",
       "      <td>302013</td>\n",
       "      <td>22.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>2793741050</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>background</td>\n",
       "      <td>ssh</td>\n",
       "      <td>success</td>\n",
       "      <td>c3ebb20a3c729dde</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>background_001</td>\n",
       "      <td>2025-09-25 22:00:02.577000+00:00</td>\n",
       "      <td>cisco_asa.log</td>\n",
       "      <td>nan</td>\n",
       "      <td>[cisco_asa.log] kind=event type=connection+sta...</td>\n",
       "      <td>3ae69698411f</td>\n",
       "      <td>3ae69698411f</td>\n",
       "      <td>3037eb8cffb1</td>\n",
       "      <td>d25837bc88b6</td>\n",
       "      <td>network</td>\n",
       "      <td>...</td>\n",
       "      <td>302013</td>\n",
       "      <td>22.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>2793741055</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>background</td>\n",
       "      <td>ssh</td>\n",
       "      <td>success</td>\n",
       "      <td>68aaafc72c7cce9c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>background_001</td>\n",
       "      <td>2025-09-25 22:00:02.861000+00:00</td>\n",
       "      <td>cisco_asa.log</td>\n",
       "      <td>nan</td>\n",
       "      <td>[cisco_asa.log] kind=event type=connection+end...</td>\n",
       "      <td>b79cefbb974c</td>\n",
       "      <td>b79cefbb974c</td>\n",
       "      <td>293c291ae824</td>\n",
       "      <td>485661e4763f</td>\n",
       "      <td>network</td>\n",
       "      <td>...</td>\n",
       "      <td>302014</td>\n",
       "      <td>22.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>4965436</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>background</td>\n",
       "      <td>ssh</td>\n",
       "      <td></td>\n",
       "      <td>a63103a021a3828a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569798</th>\n",
       "      <td>episode_016</td>\n",
       "      <td>2025-10-16 07:53:00.013000+00:00</td>\n",
       "      <td>system.security</td>\n",
       "      <td>nan</td>\n",
       "      <td>[system.security] kind=event type=admin cat=ia...</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>cf9c2f259a30</td>\n",
       "      <td>iam</td>\n",
       "      <td>...</td>\n",
       "      <td>4672</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>golden</td>\n",
       "      <td>unknown</td>\n",
       "      <td>success</td>\n",
       "      <td>row_569798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569799</th>\n",
       "      <td>episode_016</td>\n",
       "      <td>2025-10-16 07:53:00.013000+00:00</td>\n",
       "      <td>system.security</td>\n",
       "      <td>nan</td>\n",
       "      <td>[system.security] kind=event type=admin cat=ia...</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>cf9c2f259a30</td>\n",
       "      <td>iam</td>\n",
       "      <td>...</td>\n",
       "      <td>4672</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>golden</td>\n",
       "      <td>unknown</td>\n",
       "      <td>success</td>\n",
       "      <td>row_569799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569800</th>\n",
       "      <td>episode_016</td>\n",
       "      <td>2025-10-16 07:53:00.013000+00:00</td>\n",
       "      <td>system.security</td>\n",
       "      <td>nan</td>\n",
       "      <td>[system.security] kind=event type=admin cat=ia...</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>cf9c2f259a30</td>\n",
       "      <td>iam</td>\n",
       "      <td>...</td>\n",
       "      <td>4672</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>golden</td>\n",
       "      <td>unknown</td>\n",
       "      <td>success</td>\n",
       "      <td>row_569800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569801</th>\n",
       "      <td>episode_016</td>\n",
       "      <td>2025-10-16 07:53:00.013000+00:00</td>\n",
       "      <td>system.security</td>\n",
       "      <td>nan</td>\n",
       "      <td>[system.security] kind=event type=admin cat=ia...</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>cf9c2f259a30</td>\n",
       "      <td>iam</td>\n",
       "      <td>...</td>\n",
       "      <td>4672</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>golden</td>\n",
       "      <td>unknown</td>\n",
       "      <td>success</td>\n",
       "      <td>row_569801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569802</th>\n",
       "      <td>episode_016</td>\n",
       "      <td>2025-10-16 07:53:00.013000+00:00</td>\n",
       "      <td>system.security</td>\n",
       "      <td>nan</td>\n",
       "      <td>[system.security] kind=event type=admin cat=ia...</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>cf9c2f259a30</td>\n",
       "      <td>iam</td>\n",
       "      <td>...</td>\n",
       "      <td>4672</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>golden</td>\n",
       "      <td>unknown</td>\n",
       "      <td>success</td>\n",
       "      <td>row_569802</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569803 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            episode_id                        timestamp           stream  \\\n",
       "0       background_001 2025-09-25 22:00:00.494000+00:00    cisco_asa.log   \n",
       "1       background_001 2025-09-25 22:00:02.065000+00:00    cisco_asa.log   \n",
       "2       background_001 2025-09-25 22:00:02.576000+00:00    cisco_asa.log   \n",
       "3       background_001 2025-09-25 22:00:02.577000+00:00    cisco_asa.log   \n",
       "4       background_001 2025-09-25 22:00:02.861000+00:00    cisco_asa.log   \n",
       "...                ...                              ...              ...   \n",
       "569798     episode_016 2025-10-16 07:53:00.013000+00:00  system.security   \n",
       "569799     episode_016 2025-10-16 07:53:00.013000+00:00  system.security   \n",
       "569800     episode_016 2025-10-16 07:53:00.013000+00:00  system.security   \n",
       "569801     episode_016 2025-10-16 07:53:00.013000+00:00  system.security   \n",
       "569802     episode_016 2025-10-16 07:53:00.013000+00:00  system.security   \n",
       "\n",
       "       process_name                                  masked_message_cl  \\\n",
       "0               nan  [cisco_asa.log] kind=event type=connection+end...   \n",
       "1               nan  [cisco_asa.log] kind=event type=connection+sta...   \n",
       "2               nan  [cisco_asa.log] kind=event type=connection+sta...   \n",
       "3               nan  [cisco_asa.log] kind=event type=connection+sta...   \n",
       "4               nan  [cisco_asa.log] kind=event type=connection+end...   \n",
       "...             ...                                                ...   \n",
       "569798          nan  [system.security] kind=event type=admin cat=ia...   \n",
       "569799          nan  [system.security] kind=event type=admin cat=ia...   \n",
       "569800          nan  [system.security] kind=event type=admin cat=ia...   \n",
       "569801          nan  [system.security] kind=event type=admin cat=ia...   \n",
       "569802          nan  [system.security] kind=event type=admin cat=ia...   \n",
       "\n",
       "         src_ip_anon actor_ip_anon   dst_ip_anon     host_anon event_category  \\\n",
       "0       5644b8637bd0  5644b8637bd0  1cd7d76ee854  485661e4763f        network   \n",
       "1       3ae69698411f  3ae69698411f  613457f360a8  d25837bc88b6        network   \n",
       "2       3ae69698411f  3ae69698411f  613457f360a8  d25837bc88b6        network   \n",
       "3       3ae69698411f  3ae69698411f  3037eb8cffb1  d25837bc88b6        network   \n",
       "4       b79cefbb974c  b79cefbb974c  293c291ae824  485661e4763f        network   \n",
       "...              ...           ...           ...           ...            ...   \n",
       "569798          none          none          none  cf9c2f259a30            iam   \n",
       "569799          none          none          none  cf9c2f259a30            iam   \n",
       "569800          none          none          none  cf9c2f259a30            iam   \n",
       "569801          none          none          none  cf9c2f259a30            iam   \n",
       "569802          none          none          none  cf9c2f259a30            iam   \n",
       "\n",
       "        ... event_code dport ssh_method asa_conn_id gt_core gt_extended  \\\n",
       "0       ...     302014  22.0        nan     4964540   False       False   \n",
       "1       ...     302013  22.0        nan  2793740973   False       False   \n",
       "2       ...     302013  22.0        nan  2793741050   False       False   \n",
       "3       ...     302013  22.0        nan  2793741055   False       False   \n",
       "4       ...     302014  22.0        nan     4965436   False       False   \n",
       "...     ...        ...   ...        ...         ...     ...         ...   \n",
       "569798  ...       4672   nan        nan               False       False   \n",
       "569799  ...       4672   nan        nan               False       False   \n",
       "569800  ...       4672   nan        nan               False       False   \n",
       "569801  ...       4672   nan        nan               False       False   \n",
       "569802  ...       4672   nan        nan               False       False   \n",
       "\n",
       "        episode_type  dport_bucket event_outcome_norm       evidence_id  \n",
       "0         background           ssh                     922626fa84d0f2d0  \n",
       "1         background           ssh            success  e152cd0486f94fee  \n",
       "2         background           ssh            success  c3ebb20a3c729dde  \n",
       "3         background           ssh            success  68aaafc72c7cce9c  \n",
       "4         background           ssh                     a63103a021a3828a  \n",
       "...              ...           ...                ...               ...  \n",
       "569798        golden       unknown            success        row_569798  \n",
       "569799        golden       unknown            success        row_569799  \n",
       "569800        golden       unknown            success        row_569800  \n",
       "569801        golden       unknown            success        row_569801  \n",
       "569802        golden       unknown            success        row_569802  \n",
       "\n",
       "[569803 rows x 22 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "episodes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb775816-c88c-4ea5-9fad-4a8089bea299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SAVED unified episodes_df → C:\\Users\\patri\\OneDrive\\Documentos\\MASTER THESIS\\FRAMEWORK\\2025-10-16T07_27Z_ssh_alert_01\\Data Extraction\\data\\episodes_all_baseline.parquet (569,803 rows)\n"
     ]
    }
   ],
   "source": [
    "unified_path = DATASET_DIR / cfg.unified_parquet_name\n",
    "episodes_df.to_parquet(unified_path, index=False)\n",
    "print(f\"\\nSAVED unified episodes_df → {unified_path} ({len(episodes_df):,} rows)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (master_thesis_env)",
   "language": "python",
   "name": "master_thesis_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
